{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month-on-Month Topic Modelling using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "# Checking the current working directory to download the files\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique months and respective counts in Russian tweets dataset:\n",
      "2    1612\n",
      "3    8960\n",
      "4    9722\n",
      "5    2308\n",
      "Name: month, dtype: int64\n",
      "\n",
      "Unique months and respective counts in Western tweets dataset:\n",
      "2    1780\n",
      "3    7501\n",
      "4    6179\n",
      "5    1267\n",
      "Name: month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking date columns of the preprocessed .csv\n",
    "\n",
    "  # 1) Reading both .csv files\n",
    "df_r = pd.read_csv('df_r.csv')\n",
    "df_w = pd.read_csv('df_w.csv')\n",
    "\n",
    "  # 2) Getting the unique date values from each dataset\n",
    "months_df_r = df_r['month'].value_counts().sort_index()\n",
    "months_df_w = df_w['month'].value_counts().sort_index()\n",
    "\n",
    "  # 3) Printing results\n",
    "print(\"Unique months and respective counts in Russian tweets dataset:\")\n",
    "print(months_df_r)\n",
    "\n",
    "print(\"\\nUnique months and respective counts in Western tweets dataset:\")\n",
    "print(months_df_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four common months in both datasets: 2 (February), 3 (March), 4 (April), and 5 (May). We will consider these four months for further monthly LDA comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique months in the Feb Russian tweets dataset: [2]\n",
      "Unique months in the March Russian tweets dataset: [3]\n",
      "Unique months in the April Russian tweets dataset: [4]\n",
      "Unique months in the May Russian tweets dataset: [5]\n",
      "\n",
      "Unique months in the Feb Western tweets dataset: [2]\n",
      "Unique months in the March Western tweets dataset: [3]\n",
      "Unique months in the April Western tweets dataset: [4]\n",
      "Unique months in the May Western tweets dataset: [5]\n"
     ]
    }
   ],
   "source": [
    "# Splitting each of the datasets into three new files, based on the month of the tweet\n",
    "\n",
    "df_r_2 = df_r[df_r['month'] == 2]\n",
    "df_r_3 = df_r[df_r['month'] == 3]\n",
    "df_r_4 = df_r[df_r['month'] == 4]\n",
    "df_r_5 = df_r[df_r['month'] == 5]\n",
    "\n",
    "df_w_2 = df_w[df_w['month'] == 2]\n",
    "df_w_3 = df_w[df_w['month'] == 3]\n",
    "df_w_4 = df_w[df_w['month'] == 4]\n",
    "df_w_5 = df_w[df_w['month'] == 5]\n",
    "\n",
    "# Checking the month values of the new dataframes to confirm if the split was effective\n",
    "print(\"Unique months in the Feb Russian tweets dataset:\", df_r_2['month'].unique())\n",
    "print(\"Unique months in the March Russian tweets dataset:\", df_r_3['month'].unique())\n",
    "print(\"Unique months in the April Russian tweets dataset:\", df_r_4['month'].unique())\n",
    "print(\"Unique months in the May Russian tweets dataset:\", df_r_5['month'].unique())\n",
    "print(\"\")\n",
    "print(\"Unique months in the Feb Western tweets dataset:\", df_w_2['month'].unique())\n",
    "print(\"Unique months in the March Western tweets dataset:\", df_w_3['month'].unique())\n",
    "print(\"Unique months in the April Western tweets dataset:\", df_w_4['month'].unique())\n",
    "print(\"Unique months in the May Western tweets dataset:\", df_w_5['month'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed that splitting the datasets based on date was done successfully, we can save them as separate .csv files so they can be further used for new LDA monthly comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the split datasets as new .csv files to be easily accessible for further LDA analysis\n",
    "\n",
    "df_r_2.to_csv('df_r_2.csv', index = False)\n",
    "df_r_3.to_csv('df_r_3.csv', index = False)\n",
    "df_r_4.to_csv('df_r_4.csv', index = False)\n",
    "df_r_5.to_csv('df_r_5.csv', index = False)\n",
    "\n",
    "df_w_2.to_csv('df_w_2.csv', index = False)\n",
    "df_w_3.to_csv('df_w_3.csv', index = False)\n",
    "df_w_4.to_csv('df_w_4.csv', index = False)\n",
    "df_w_5.to_csv('df_w_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the Feb Russian tweets dataset: 1612\n",
      "Number of rows in the March Russian tweets dataset: 8960\n",
      "Number of rows in the April Russian tweets dataset: 9722\n",
      "Number of rows in the May Russian tweets dataset: 2308\n",
      "\n",
      "Number of rows in the Feb Western tweets dataset: 1780\n",
      "Number of rows in the March Western tweets dataset: 7501\n",
      "Number of rows in the April Western tweets dataset: 6179\n",
      "Number of rows in the May Western tweets dataset: 1267\n"
     ]
    }
   ],
   "source": [
    "# Checking if the new .csv files were successfuly saved\n",
    "\n",
    "df_r_2 = pd.read_csv('df_r_2.csv')\n",
    "df_r_3 = pd.read_csv('df_r_3.csv')\n",
    "df_r_4 = pd.read_csv('df_r_4.csv')\n",
    "df_r_5 = pd.read_csv('df_r_5.csv')\n",
    "\n",
    "df_w_2 = pd.read_csv('df_w_2.csv')\n",
    "df_w_3 = pd.read_csv('df_w_3.csv')\n",
    "df_w_4 = pd.read_csv('df_w_4.csv')\n",
    "df_w_5 = pd.read_csv('df_w_5.csv')\n",
    "\n",
    "# Checking if the number of rows in the new dataframes match with the value counts of each month\n",
    "print(\"Number of rows in the Feb Russian tweets dataset:\", df_r_2.shape[0])\n",
    "print(\"Number of rows in the March Russian tweets dataset:\", df_r_3.shape[0])\n",
    "print(\"Number of rows in the April Russian tweets dataset:\", df_r_4.shape[0])\n",
    "print(\"Number of rows in the May Russian tweets dataset:\", df_r_5.shape[0])\n",
    "print(\"\")\n",
    "print(\"Number of rows in the Feb Western tweets dataset:\", df_w_2.shape[0])\n",
    "print(\"Number of rows in the March Western tweets dataset:\", df_w_3.shape[0])\n",
    "print(\"Number of rows in the April Western tweets dataset:\", df_w_4.shape[0])\n",
    "print(\"Number of rows in the May Western tweets dataset:\", df_w_5.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows in each of the new .csv files matches the value counts of each month in the preprocessed dataframes, indicating that the new files are now ready to be reused in the LDA analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instaling the necessary packages and libraries\n",
    "%pip install pandas==1.5.3 # THIS VERSION OF PANDAS MUST BE INSTALLED TO BE COMPATIBLE WITH pyLDAvis\n",
    "%pip install pyLDAvis\n",
    "%pip install pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new monthly TF-IDF corpus to pass onto the LDA model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
